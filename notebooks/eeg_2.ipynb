{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import annotations\n",
    "\n",
    "#import random\n",
    "#import shutil\n",
    "#from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterator, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from loguru import logger\n",
    "#from torch.nn.utils.rnn import pad_sequence\n",
    "#from tqdm import tqdm\n",
    "from scipy.io import arff\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "Tensor = torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eeg(data_dir: Path=\"../data/raw\") -> Path:\n",
    "    dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\"  # noqa: E501\n",
    "    datapath = tf.keras.utils.get_file(\n",
    "        \"eeg_data\", origin=dataset_url, untar=False, cache_dir=data_dir\n",
    "    )\n",
    "\n",
    "    datapath = Path(datapath)\n",
    "    logger.info(f\"Data is downloaded to {datapath}.\")\n",
    "    return datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "\n",
    "class BaseDataset:\n",
    "    def __init__(self, datapath: Path) -> None:\n",
    "        self.path = datapath\n",
    "        self.data =  self.process_data()\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        data = arff.loadarff(self.path)\n",
    "        cur_label = int(data[0][0][14]) #index 14 = label\n",
    "        EEG_list = [] #Lege lijst waarin meerdere observaties worden opgeslagen\n",
    "        EEG_full = [] #Lege lijst waarin meerdere batches in worden samengevoegd.\n",
    "        for obs in data[0]:\n",
    "            if int(obs[14]) == cur_label:\n",
    "                EEG_dim = [] #Lege lijst waarin de EEG_dim van een bepaalde observatie in kunnen worden opgeslagen.\n",
    "                for index, i in enumerate(obs):\n",
    "                    if index != 14:\n",
    "                        EEG_dim.append(i)\n",
    "                EEG_dim = torch.Tensor(EEG_dim)\n",
    "                EEG_list.append(EEG_dim)\n",
    "            else:\n",
    "                EEG_full_label = (cur_label, torch.stack(EEG_list))\n",
    "                EEG_full.append(EEG_full_label)\n",
    "                cur_label = int(obs[14])\n",
    "                EEG_list = [] #Lege lijst waarin meerdere observaties in kunnen worden opgeslagen.\n",
    "                EEG_dim = [] #Lege lijst waarin de EEG_dim van een bepaalde observatie in kunnen worden opgeslagen.\n",
    "                for index, i in enumerate(obs):\n",
    "                    if index != 14:\n",
    "                        EEG_dim.append(i)\n",
    "                EEG_dim = torch.Tensor(EEG_dim)\n",
    "                EEG_list.append(EEG_dim)\n",
    "        EEG_full_label = (cur_label, torch.stack(EEG_list))\n",
    "        EEG_full.append(EEG_full_label)\n",
    "        return EEG_full\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "   \n",
    "    def __getitem__(self, idx: int) -> Tuple:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 11:42:12.780 | INFO     | __main__:get_eeg:8 - Data is downloaded to ../data/raw/datasets/eeg_data.\n"
     ]
    }
   ],
   "source": [
    "dataloader = BaseDataset(datapath=get_eeg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([188, 14])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dataloader[0]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataIterator_pad:\n",
    "    \"\"\"This iterator will consume all data and stop automatically.\n",
    "    The dataset should have a:\n",
    "        __len__ method\n",
    "        __getitem__ method\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: BaseDataset, window_size: int) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.ws = window_size\n",
    "        self.data = self.padding() \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def padding(self) -> None:\n",
    "        data = self.dataset\n",
    "        window_size = self.ws\n",
    "        list_padded = []\n",
    "        for i in range(24):\n",
    "            len_chunck = len(data[i][1])\n",
    "            diff = len_chunck % window_size\n",
    "            pad_value = window_size - diff\n",
    "            if diff != 0:\n",
    "                new_data = F.pad(input=data[i][1], pad=(0, 0, 0, pad_value), mode='constant', value=0)\n",
    "                new_data2 = (data[i][0], new_data)\n",
    "                list_padded.append(new_data2)\n",
    "            else:\n",
    "                new_data3 = (data[i][0], data[i][1])\n",
    "                list_padded.append(new_data3)\n",
    "        return list_padded\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple:\n",
    "        return self.data[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test6 = BaseDataIterator_pad(dataloader,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "         4393.8501],\n",
       "        [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "         4384.1001],\n",
       "        [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "         4389.2300],\n",
       "        ...,\n",
       "        [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "         4549.2300],\n",
       "        [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "            0.0000],\n",
       "        [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "            0.0000]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y= test6[0]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 60, 14])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_window = len(test6[23][1])\n",
    "n_window\n",
    "time = torch.arange(0, 60).reshape(1, -1)\n",
    "time\n",
    "window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "window\n",
    "idx = time + window\n",
    "idx.shape\n",
    "idx = idx - 60 + 1 \n",
    "idx.shape\n",
    "test = test6[23][1][idx]\n",
    "test\n",
    "test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = torch.arange(0, 5).reshape(1, -1) \n",
    "window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "idx = time + window\n",
    "n_window\n",
    "test = test6[0][1][idx]\n",
    "\n",
    "test = test6[0][1][idx]\n",
    "test2 = (test6[i][0], test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataIterator_pad2:\n",
    "    \"\"\"This iterator will consume all data and stop automatically.\n",
    "    The dataset should have a:\n",
    "        __len__ method\n",
    "        __getitem__ method\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: BaseDataset, window_size: int) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.ws = window_size\n",
    "        self.data = self.padding_wind() \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def padding_wind(self) -> None:\n",
    "        data = self.dataset\n",
    "        window_size = self.ws\n",
    "        list2 = []\n",
    "        list_padded = []\n",
    "        for i in range(24):\n",
    "            len_chunck = len(data[i][1])\n",
    "            diff = len_chunck % window_size\n",
    "            pad_value = window_size - diff\n",
    "            if diff != 0:\n",
    "                new_data = F.pad(input=data[i][1], pad=(0, 0, 0, pad_value), mode='constant', value=0)\n",
    "                new_data2 = (data[i][0], new_data)\n",
    "                list_padded.append(new_data2)\n",
    "                n_window = len(list_padded[i][1]) \n",
    "                time = torch.arange(0, window_size).reshape(1, -1)\n",
    "                window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "                idx = time + window\n",
    "                idx = idx - window_size + 1\n",
    "                test = list_padded[i][1][idx]\n",
    "                test2 = (list_padded[i][0], test)\n",
    "                list2.append(test2)\n",
    "            else:\n",
    "                new_data3 = (data[i][0], data[i][1])\n",
    "                list_padded.append(new_data3)\n",
    "                n_window = len(list_padded[i][1])\n",
    "                time = torch.arange(0, window_size).reshape(1, -1)\n",
    "                window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "                idx = time + window\n",
    "                idx = idx - window_size + 1\n",
    "                test = list_padded[i][1][idx]\n",
    "                test2 = (list_padded[i][0], test)\n",
    "                list2.append(test2)\n",
    "        return list2\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple:\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test88 = BaseDataIterator_pad2(dataloader,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataIterator_wind:\n",
    "    \"\"\"This iterator will consume all data and stop automatically.\n",
    "    The dataset should have a:\n",
    "        __len__ method\n",
    "        __getitem__ method\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: BaseDataset, window_size: int) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.ws = window_size\n",
    "        self.data = self.window()\n",
    "        \n",
    "   \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def window(self) -> None:\n",
    "        data = self.dataset\n",
    "        list2 = []\n",
    "        ws = self.ws\n",
    "        for i in range(24):\n",
    "            n_window = len(data[i][1]) \n",
    "            time = torch.arange(0, ws).reshape(1, -1)\n",
    "            window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "            idx = time + window\n",
    "            idx = idx - ws + 1\n",
    "            test = data[i][1][idx]\n",
    "            test2 = (data[i][0], test)\n",
    "            list2.append(test2)\n",
    "        return list2\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple:\n",
    "        return self.data[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "test66 = BaseDataIterator_wind(test6,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 14])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dataloader[23]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " tensor([[4312.3101, 4022.0500, 4278.4600, 4149.2300, 4336.9199, 4623.5898,\n",
       "          4081.5400, 4639.4902, 4214.3599, 4230.7700, 4186.6699, 4284.6201,\n",
       "          4612.3101, 4368.2100],\n",
       "         [4304.1001, 4016.9199, 4273.8501, 4145.1299, 4340.0000, 4623.5898,\n",
       "          4084.1001, 4646.6699, 4223.0801, 4229.2300, 4182.0498, 4282.5601,\n",
       "          4606.1499, 4364.1001],\n",
       "         [4303.0801, 4016.9199, 4270.7700, 4138.9702, 4342.0498, 4621.5400,\n",
       "          4082.5601, 4645.6401, 4220.0000, 4229.2300, 4180.5098, 4276.9199,\n",
       "          4602.0498, 4362.5601],\n",
       "         [4304.6201, 4018.4600, 4272.3101, 4139.4902, 4340.0000, 4619.4902,\n",
       "          4082.5601, 4637.9502, 4203.0801, 4226.6699, 4179.4902, 4278.4600,\n",
       "          4602.0498, 4360.0000],\n",
       "         [4301.0298, 4013.8501, 4268.7202, 4140.0000, 4341.0298, 4617.4399,\n",
       "          4082.0500, 4626.1499, 4196.4102, 4224.1001, 4177.9502, 4278.9702,\n",
       "          4603.0801, 4360.0000],\n",
       "         [4300.0000, 4009.2300, 4263.5898, 4138.4600, 4342.5601, 4617.9502,\n",
       "          4083.5901, 4623.0801, 4205.6401, 4226.6699, 4177.9502, 4277.4399,\n",
       "          4601.0298, 4362.0498],\n",
       "         [4302.5601, 4008.7200, 4265.1299, 4138.9702, 4336.4102, 4618.4600,\n",
       "          4088.7200, 4630.7700, 4211.7900, 4227.1802, 4178.4600, 4278.4600,\n",
       "          4602.0498, 4359.4902],\n",
       "         [4297.9502, 4006.1499, 4266.1499, 4136.9199, 4330.7700, 4615.8999,\n",
       "          4088.2100, 4631.7900, 4207.6899, 4225.1299, 4176.4102, 4277.9502,\n",
       "          4605.6401, 4354.8701],\n",
       "         [4293.8501, 4005.1299, 4262.5601, 4134.8701, 4332.8198, 4614.3599,\n",
       "          4083.5901, 4629.2300, 4204.6201, 4225.1299, 4174.8701, 4276.9199,\n",
       "          4602.0498, 4352.3101],\n",
       "         [4298.9702, 4006.6699, 4261.0298, 4137.4399, 4337.9502, 4615.3799,\n",
       "          4087.1799, 4634.8701, 4207.6899, 4227.6899, 4176.4102, 4277.9502,\n",
       "          4599.4902, 4350.7700],\n",
       "         [4296.9199, 4006.1499, 4264.1001, 4134.8701, 4339.4902, 4619.4902,\n",
       "          4090.2600, 4633.3301, 4206.1499, 4229.2300, 4180.5098, 4278.9702,\n",
       "          4606.6699, 4351.2798],\n",
       "         [4289.2300, 4003.0801, 4263.5898, 4124.6201, 4338.4600, 4621.0298,\n",
       "          4084.1001, 4625.1299, 4200.5098, 4226.6699, 4180.0000, 4279.4902,\n",
       "          4609.2300, 4354.3599],\n",
       "         [4288.7202, 3999.4900, 4254.3599, 4120.5098, 4336.9199, 4618.9702,\n",
       "          4082.5601, 4630.2598, 4207.1802, 4226.1499, 4177.9502, 4281.0298,\n",
       "          4605.1299, 4351.7900],\n",
       "         [4288.2100, 3995.8999, 4248.2100, 4120.0000, 4334.3599, 4615.8999,\n",
       "          4084.6201, 4641.0298, 4214.3599, 4228.7202, 4178.4600, 4273.8501,\n",
       "          4600.0000, 4343.0801],\n",
       "         [4282.5601, 3991.7900, 4250.2598, 4115.8999, 4332.3101, 4612.8198,\n",
       "          4077.4399, 4639.4902, 4210.7700, 4225.6401, 4175.3799, 4267.6899,\n",
       "          4595.8999, 4340.0000],\n",
       "         [4280.5098, 3988.7200, 4249.2300, 4116.9199, 4332.3101, 4612.8198,\n",
       "          4072.3101, 4632.3101, 4207.6899, 4220.0000, 4173.8501, 4271.2798,\n",
       "          4595.3799, 4343.0801],\n",
       "         [4281.0298, 3990.2600, 4245.6401, 4116.9199, 4333.8501, 4614.3599,\n",
       "          4074.8701, 4625.6401, 4203.0801, 4221.5400, 4171.2798, 4269.2300,\n",
       "          4593.3301, 4340.5098],\n",
       "         [4276.9199, 3991.7900, 4245.1299, 4110.7700, 4332.8198, 4615.3799,\n",
       "          4073.3301, 4621.5400, 4194.3599, 4217.4399, 4162.5601, 4259.4902,\n",
       "          4590.2598, 4333.3301],\n",
       "         [4277.4399, 3990.7700, 4246.6699, 4113.8501, 4333.3301, 4615.3799,\n",
       "          4072.8201, 4623.5898, 4193.3301, 4212.8198, 4160.5098, 4257.9502,\n",
       "          4591.7900, 4339.4902],\n",
       "         [4284.6201, 3991.7900, 4251.2798, 4122.0498, 4334.3599, 4616.4102,\n",
       "          4080.5100, 4628.7202, 4200.0000, 4220.0000, 4165.6401, 4267.1802,\n",
       "          4596.4102, 4350.7700],\n",
       "         [4287.6899, 3997.4399, 4260.0000, 4121.0298, 4333.3301, 4616.4102,\n",
       "          4088.7200, 4638.4600, 4212.3101, 4226.6699, 4167.6899, 4274.3599,\n",
       "          4597.9502, 4350.7700]]))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 60, 14])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = test66[23]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " tensor([[4312.3101, 4022.0500, 4278.4600, 4149.2300, 4336.9199, 4623.5898,\n",
       "          4081.5400, 4639.4902, 4214.3599, 4230.7700, 4186.6699, 4284.6201,\n",
       "          4612.3101, 4368.2100],\n",
       "         [4304.1001, 4016.9199, 4273.8501, 4145.1299, 4340.0000, 4623.5898,\n",
       "          4084.1001, 4646.6699, 4223.0801, 4229.2300, 4182.0498, 4282.5601,\n",
       "          4606.1499, 4364.1001],\n",
       "         [4303.0801, 4016.9199, 4270.7700, 4138.9702, 4342.0498, 4621.5400,\n",
       "          4082.5601, 4645.6401, 4220.0000, 4229.2300, 4180.5098, 4276.9199,\n",
       "          4602.0498, 4362.5601],\n",
       "         [4304.6201, 4018.4600, 4272.3101, 4139.4902, 4340.0000, 4619.4902,\n",
       "          4082.5601, 4637.9502, 4203.0801, 4226.6699, 4179.4902, 4278.4600,\n",
       "          4602.0498, 4360.0000],\n",
       "         [4301.0298, 4013.8501, 4268.7202, 4140.0000, 4341.0298, 4617.4399,\n",
       "          4082.0500, 4626.1499, 4196.4102, 4224.1001, 4177.9502, 4278.9702,\n",
       "          4603.0801, 4360.0000],\n",
       "         [4300.0000, 4009.2300, 4263.5898, 4138.4600, 4342.5601, 4617.9502,\n",
       "          4083.5901, 4623.0801, 4205.6401, 4226.6699, 4177.9502, 4277.4399,\n",
       "          4601.0298, 4362.0498],\n",
       "         [4302.5601, 4008.7200, 4265.1299, 4138.9702, 4336.4102, 4618.4600,\n",
       "          4088.7200, 4630.7700, 4211.7900, 4227.1802, 4178.4600, 4278.4600,\n",
       "          4602.0498, 4359.4902],\n",
       "         [4297.9502, 4006.1499, 4266.1499, 4136.9199, 4330.7700, 4615.8999,\n",
       "          4088.2100, 4631.7900, 4207.6899, 4225.1299, 4176.4102, 4277.9502,\n",
       "          4605.6401, 4354.8701],\n",
       "         [4293.8501, 4005.1299, 4262.5601, 4134.8701, 4332.8198, 4614.3599,\n",
       "          4083.5901, 4629.2300, 4204.6201, 4225.1299, 4174.8701, 4276.9199,\n",
       "          4602.0498, 4352.3101],\n",
       "         [4298.9702, 4006.6699, 4261.0298, 4137.4399, 4337.9502, 4615.3799,\n",
       "          4087.1799, 4634.8701, 4207.6899, 4227.6899, 4176.4102, 4277.9502,\n",
       "          4599.4902, 4350.7700],\n",
       "         [4296.9199, 4006.1499, 4264.1001, 4134.8701, 4339.4902, 4619.4902,\n",
       "          4090.2600, 4633.3301, 4206.1499, 4229.2300, 4180.5098, 4278.9702,\n",
       "          4606.6699, 4351.2798],\n",
       "         [4289.2300, 4003.0801, 4263.5898, 4124.6201, 4338.4600, 4621.0298,\n",
       "          4084.1001, 4625.1299, 4200.5098, 4226.6699, 4180.0000, 4279.4902,\n",
       "          4609.2300, 4354.3599],\n",
       "         [4288.7202, 3999.4900, 4254.3599, 4120.5098, 4336.9199, 4618.9702,\n",
       "          4082.5601, 4630.2598, 4207.1802, 4226.1499, 4177.9502, 4281.0298,\n",
       "          4605.1299, 4351.7900],\n",
       "         [4288.2100, 3995.8999, 4248.2100, 4120.0000, 4334.3599, 4615.8999,\n",
       "          4084.6201, 4641.0298, 4214.3599, 4228.7202, 4178.4600, 4273.8501,\n",
       "          4600.0000, 4343.0801],\n",
       "         [4282.5601, 3991.7900, 4250.2598, 4115.8999, 4332.3101, 4612.8198,\n",
       "          4077.4399, 4639.4902, 4210.7700, 4225.6401, 4175.3799, 4267.6899,\n",
       "          4595.8999, 4340.0000],\n",
       "         [4280.5098, 3988.7200, 4249.2300, 4116.9199, 4332.3101, 4612.8198,\n",
       "          4072.3101, 4632.3101, 4207.6899, 4220.0000, 4173.8501, 4271.2798,\n",
       "          4595.3799, 4343.0801],\n",
       "         [4281.0298, 3990.2600, 4245.6401, 4116.9199, 4333.8501, 4614.3599,\n",
       "          4074.8701, 4625.6401, 4203.0801, 4221.5400, 4171.2798, 4269.2300,\n",
       "          4593.3301, 4340.5098],\n",
       "         [4276.9199, 3991.7900, 4245.1299, 4110.7700, 4332.8198, 4615.3799,\n",
       "          4073.3301, 4621.5400, 4194.3599, 4217.4399, 4162.5601, 4259.4902,\n",
       "          4590.2598, 4333.3301],\n",
       "         [4277.4399, 3990.7700, 4246.6699, 4113.8501, 4333.3301, 4615.3799,\n",
       "          4072.8201, 4623.5898, 4193.3301, 4212.8198, 4160.5098, 4257.9502,\n",
       "          4591.7900, 4339.4902],\n",
       "         [4284.6201, 3991.7900, 4251.2798, 4122.0498, 4334.3599, 4616.4102,\n",
       "          4080.5100, 4628.7202, 4200.0000, 4220.0000, 4165.6401, 4267.1802,\n",
       "          4596.4102, 4350.7700],\n",
       "         [4287.6899, 3997.4399, 4260.0000, 4121.0298, 4333.3301, 4616.4102,\n",
       "          4088.7200, 4638.4600, 4212.3101, 4226.6699, 4167.6899, 4274.3599,\n",
       "          4597.9502, 4350.7700],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000]]))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test6[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " tensor([[[4304.1001, 4016.9199, 4273.8501,  ..., 4282.5601, 4606.1499,\n",
       "           4364.1001],\n",
       "          [4303.0801, 4016.9199, 4270.7700,  ..., 4276.9199, 4602.0498,\n",
       "           4362.5601],\n",
       "          [4304.6201, 4018.4600, 4272.3101,  ..., 4278.4600, 4602.0498,\n",
       "           4360.0000],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [4312.3101, 4022.0500, 4278.4600,  ..., 4284.6201, 4612.3101,\n",
       "           4368.2100]],\n",
       " \n",
       "         [[4303.0801, 4016.9199, 4270.7700,  ..., 4276.9199, 4602.0498,\n",
       "           4362.5601],\n",
       "          [4304.6201, 4018.4600, 4272.3101,  ..., 4278.4600, 4602.0498,\n",
       "           4360.0000],\n",
       "          [4301.0298, 4013.8501, 4268.7202,  ..., 4278.9702, 4603.0801,\n",
       "           4360.0000],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [4312.3101, 4022.0500, 4278.4600,  ..., 4284.6201, 4612.3101,\n",
       "           4368.2100],\n",
       "          [4304.1001, 4016.9199, 4273.8501,  ..., 4282.5601, 4606.1499,\n",
       "           4364.1001]],\n",
       " \n",
       "         [[4304.6201, 4018.4600, 4272.3101,  ..., 4278.4600, 4602.0498,\n",
       "           4360.0000],\n",
       "          [4301.0298, 4013.8501, 4268.7202,  ..., 4278.9702, 4603.0801,\n",
       "           4360.0000],\n",
       "          [4300.0000, 4009.2300, 4263.5898,  ..., 4277.4399, 4601.0298,\n",
       "           4362.0498],\n",
       "          ...,\n",
       "          [4312.3101, 4022.0500, 4278.4600,  ..., 4284.6201, 4612.3101,\n",
       "           4368.2100],\n",
       "          [4304.1001, 4016.9199, 4273.8501,  ..., 4282.5601, 4606.1499,\n",
       "           4364.1001],\n",
       "          [4303.0801, 4016.9199, 4270.7700,  ..., 4276.9199, 4602.0498,\n",
       "           4362.5601]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [4312.3101, 4022.0500, 4278.4600,  ..., 4284.6201, 4612.3101,\n",
       "           4368.2100],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000]],\n",
       " \n",
       "         [[   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [4312.3101, 4022.0500, 4278.4600,  ..., 4284.6201, 4612.3101,\n",
       "           4368.2100],\n",
       "          [4304.1001, 4016.9199, 4273.8501,  ..., 4282.5601, 4606.1499,\n",
       "           4364.1001],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000]],\n",
       " \n",
       "         [[4312.3101, 4022.0500, 4278.4600,  ..., 4284.6201, 4612.3101,\n",
       "           4368.2100],\n",
       "          [4304.1001, 4016.9199, 4273.8501,  ..., 4282.5601, 4606.1499,\n",
       "           4364.1001],\n",
       "          [4303.0801, 4016.9199, 4270.7700,  ..., 4276.9199, 4602.0498,\n",
       "           4362.5601],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000]]]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test66[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataIterator:\n",
    "    \"\"\"This iterator will consume all data and stop automatically.\n",
    "    The dataset should have a:\n",
    "        __len__ method\n",
    "        __getitem__ method\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: BaseDataset, batchsize: int) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.buffer = self.buffer[batchsize:]\n",
    "        self.batchsize = batchsize\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(len(self.dataset) / self.batchsize)\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator:\n",
    "        self.index = 0\n",
    "        self.index_list = torch.randperm(len(self.dataset))\n",
    "        return self\n",
    "\n",
    "\n",
    "    def batchloop(self) -> Tuple[List, List]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        for _ in range(self.batchsize):\n",
    "            x, y = self.dataset[int(self.index_list[self.index])]\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "            self.index += 1\n",
    "        return X, Y\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.dataset) - self.batchsize):\n",
    "            X, Y = self.batchloop()  # noqa N806\n",
    "            return torch.tensor(X), torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "   \n",
    "    def __getitem__(self, idx: int) -> Tuple:\n",
    "        return self.dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test55 = BaseDataIterator(test88,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test55.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indien de chunk lengte niet deelbaar is door de window size dan padden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "x = 188 % window_size\n",
    "pad = window_size - x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf41673808a97226fd1716a8b076843c01d654ce418b73454e0f22407fa0bee6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deep-learning-0fXQ8KaZ-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
