{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excercise 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, \"..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haal de data op vanuit de functie in de gestructeerde folder indeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import make_dataset\n",
    "from src.data import data_tools\n",
    "\n",
    "from typing import Callable, Dict, Iterator, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "Tensor = torch.Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-12 10:39:43.510 | INFO     | src.data.make_dataset:get_eeg:38 - Data is downloaded to /tmp/.keras/datasets/eeg.\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset.get_eeg()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Na een verkenning van de data, komt naar voren dat de datset uit 14 dimensies staat.De data wordt eerst ingeladen in chunks wanneer het label gelijk is. Hierbij wordt dus de data aan elkaar geclusterd wanneer het label gelijk blijft. Dit wordt gedaan door middel van de class BaseDataset waarbij ik een functie ingebouwd heb waarbij de data wordt aangepast (process_data). Hierbij kijk ik eerst naar het huidige label (cur_label = index 14) en maak ik 2 lege lijsten aan. 1 lijst waar meerdere observaties (EEG_list) aan elkaar worden opgeslagen en 1 lijst waar alle chunks worden samengevoegd (chunks). Waarbij ik gebruik maak van een forloop en kijk telkens of het label gelijk is aan het huidige label en hierna pak ik alle indexen behalve index 14 ( = label). Deze voeg ik toe aan de een lege lijst (EEG_dim) en uiteindelijk aan de lijst buiten de forloop (EEG_list). Dit doe ik ook als het label niet gelijk is aan huidig label. Uiteindelijk voeg ik de lijsten weer bij elkaar in de list chunks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data_tools.BaseDataset(datapath=dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbij komen 24 chunks naar voren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([[4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "          4393.8501],\n",
       "         [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "          4384.1001],\n",
       "         [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "          4389.2300],\n",
       "         ...,\n",
       "         [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "          4571.7900],\n",
       "         [4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "          4558.4600],\n",
       "         [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "          4549.2300]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, torch.Size([188, 14]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dataloader[0]\n",
    "x, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbij zie je dus dat de eerste chunk uit een sequence lengte van 188 bij 14 dimensies bestaat met label 0. De tweede observatie een sequence lengte van 683 bij 14 dimensies heeft met label 1. Om dit te kunnen batchen kunnen we gebruik maken van een window functie. Deze heb ik een de BaseDataIterator toegevoegd (class BaseDataIterator_wind). Hierbij maak ik gebruik van de class van de BaseDataset en heb hierbij een functie window ingebouwd. Hierbij heb ik als basis de window functie uit les 3 gebruikt en maak ik weer een lege lijst aan. Hierna maak ik weer gebruik van een forloop waarbij ik door de 24 chunks van de dataset ga (len(self.dataset)). Hierbij kijk ik dus per chunk hoelang de sequence lengte is en wordt er gekeken hoevaak de window erdoor heen kan.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_data = data_tools.BaseDataIterator_wind(dataloader, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_data.__len__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In onderstaande uitdraai zie je het eerste item in combinatie met een window van 5, waarbij het tweede gedeelte dus ook met de tweede waarde begint (4468). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([[[4465.1299, 4041.5400, 4298.4600,  ..., 4358.4600, 4814.3599,\n",
       "           4566.1499],\n",
       "          [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "           4571.7900],\n",
       "          [4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "           4558.4600],\n",
       "          [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "           4549.2300],\n",
       "          [4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "           4393.8501]],\n",
       " \n",
       "         [[4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "           4571.7900],\n",
       "          [4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "           4558.4600],\n",
       "          [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "           4549.2300],\n",
       "          [4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "           4393.8501],\n",
       "          [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "           4384.1001]],\n",
       " \n",
       "         [[4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "           4558.4600],\n",
       "          [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "           4549.2300],\n",
       "          [4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "           4393.8501],\n",
       "          [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "           4384.1001],\n",
       "          [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "           4389.2300]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[4450.7700, 4045.1299, 4289.7402,  ..., 4348.2100, 4774.8701,\n",
       "           4537.4399],\n",
       "          [4448.7202, 4042.5601, 4275.3799,  ..., 4339.4902, 4785.6401,\n",
       "           4542.0498],\n",
       "          [4454.8701, 4039.4900, 4281.0298,  ..., 4345.6401, 4796.9199,\n",
       "           4551.7900],\n",
       "          [4465.1299, 4041.5400, 4298.4600,  ..., 4358.4600, 4814.3599,\n",
       "           4566.1499],\n",
       "          [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "           4571.7900]],\n",
       " \n",
       "         [[4448.7202, 4042.5601, 4275.3799,  ..., 4339.4902, 4785.6401,\n",
       "           4542.0498],\n",
       "          [4454.8701, 4039.4900, 4281.0298,  ..., 4345.6401, 4796.9199,\n",
       "           4551.7900],\n",
       "          [4465.1299, 4041.5400, 4298.4600,  ..., 4358.4600, 4814.3599,\n",
       "           4566.1499],\n",
       "          [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "           4571.7900],\n",
       "          [4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "           4558.4600]],\n",
       " \n",
       "         [[4454.8701, 4039.4900, 4281.0298,  ..., 4345.6401, 4796.9199,\n",
       "           4551.7900],\n",
       "          [4465.1299, 4041.5400, 4298.4600,  ..., 4358.4600, 4814.3599,\n",
       "           4566.1499],\n",
       "          [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "           4571.7900],\n",
       "          [4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "           4558.4600],\n",
       "          [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "           4549.2300]]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_data.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, torch.Size([188, 5, 14]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = window_data[0]\n",
    "x, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Kijken naar de eerste observatie. Met een window van 5 is de observatie eingelijk te kort ( moet dan 190 zijn) en wordt dus niet de gehele observatie gewindowed. Daarnaast mag de window ook niet te groot zijn. Om deze reden wordt padding toegevoegd. Deze heb ik in een aparte class geschreven waarbij ik de functie padding gebruik. Hierbij maak ik weer een lege lijst waar ik met een forloop door de chunks (24) heen ga. Hierbij kijk ik telkens hoelang de sequence lengte is en bereken ik het verschil met de windowsize door middel van een modula functie (%). Hierbij kijk ik naar het verschil. Stel dit verschil is niet 0 dan wordt deze door midde lvan de F.pad functie toegevoegd. Als deze gelijk is aan 0 wordt er geen extra padding toegepast. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_padding = data_tools.BaseDataIterator_pad(dataloader, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_padding.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([[4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "          4393.8501],\n",
       "         [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "          4384.1001],\n",
       "         [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "          4389.2300],\n",
       "         ...,\n",
       "         [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "          4549.2300],\n",
       "         [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "             0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "             0.0000]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_padding.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbij zie je dus bij de eerste observatie dat de sequence lengte is uitegebreid met 2 ( naar 190), zodat de windowing van 5 nu wel goed gaat en geen data wordt overslagen. Daarnaast is het nu ook mogelijk om een grotere window te gebruiken, aangezien de observaties met een lager aan sequence lengtes aangevuld worden door middel van de padding. De windowing en padding heb ik gecombineerd in één class, waarbij ook de batchloop is toegevoegd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ex2 = data_tools.BaseDataIterator_pad_wind(dataloader, 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([[[4450.7700, 4045.1299, 4289.7402,  ..., 4348.2100, 4774.8701,\n",
       "           4537.4399],\n",
       "          [4448.7202, 4042.5601, 4275.3799,  ..., 4339.4902, 4785.6401,\n",
       "           4542.0498],\n",
       "          [4454.8701, 4039.4900, 4281.0298,  ..., 4345.6401, 4796.9199,\n",
       "           4551.7900],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "           4393.8501]],\n",
       " \n",
       "         [[4448.7202, 4042.5601, 4275.3799,  ..., 4339.4902, 4785.6401,\n",
       "           4542.0498],\n",
       "          [4454.8701, 4039.4900, 4281.0298,  ..., 4345.6401, 4796.9199,\n",
       "           4551.7900],\n",
       "          [4465.1299, 4041.5400, 4298.4600,  ..., 4358.4600, 4814.3599,\n",
       "           4566.1499],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "           4393.8501],\n",
       "          [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "           4384.1001]],\n",
       " \n",
       "         [[4454.8701, 4039.4900, 4281.0298,  ..., 4345.6401, 4796.9199,\n",
       "           4551.7900],\n",
       "          [4465.1299, 4041.5400, 4298.4600,  ..., 4358.4600, 4814.3599,\n",
       "           4566.1499],\n",
       "          [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "           4571.7900],\n",
       "          ...,\n",
       "          [4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "           4393.8501],\n",
       "          [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "           4384.1001],\n",
       "          [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "           4389.2300]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[4463.5898, 4072.8201, 4300.5098,  ..., 4351.7900, 4780.0000,\n",
       "           4545.6401],\n",
       "          [4461.0298, 4063.0801, 4297.9502,  ..., 4355.8999, 4786.1499,\n",
       "           4555.8999],\n",
       "          [4457.4399, 4050.7700, 4299.4902,  ..., 4358.9702, 4781.5400,\n",
       "           4548.2100],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000]],\n",
       " \n",
       "         [[4461.0298, 4063.0801, 4297.9502,  ..., 4355.8999, 4786.1499,\n",
       "           4555.8999],\n",
       "          [4457.4399, 4050.7700, 4299.4902,  ..., 4358.9702, 4781.5400,\n",
       "           4548.2100],\n",
       "          [4450.7700, 4045.1299, 4289.7402,  ..., 4348.2100, 4774.8701,\n",
       "           4537.4399],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000]],\n",
       " \n",
       "         [[4457.4399, 4050.7700, 4299.4902,  ..., 4358.9702, 4781.5400,\n",
       "           4548.2100],\n",
       "          [4450.7700, 4045.1299, 4289.7402,  ..., 4348.2100, 4774.8701,\n",
       "           4537.4399],\n",
       "          [4448.7202, 4042.5601, 4275.3799,  ..., 4339.4902, 4785.6401,\n",
       "           4542.0498],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000]]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ex2.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, torch.Size([240, 60, 14]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data_ex2[0]\n",
    "x, y.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deep-learning-E14Cnx23-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16b8f312320cd240106b9ea4d318428341e8727b3c7d5fc1f73cfe4a3d9868ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
