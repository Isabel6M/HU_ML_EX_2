{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 12:08:04.989830: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-10 12:08:04.989865: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#from __future__ import annotations\n",
    "\n",
    "#import random\n",
    "#import shutil\n",
    "#from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterator, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from loguru import logger\n",
    "#from torch.nn.utils.rnn import pad_sequence\n",
    "#from tqdm import tqdm\n",
    "from scipy.io import arff\n",
    "\n",
    "Tensor = torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eeg(data_dir: Path=\"../data/raw\") -> Path:\n",
    "    dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\"  # noqa: E501\n",
    "    datapath = tf.keras.utils.get_file(\n",
    "        \"eeg_data\", origin=dataset_url, untar=False, cache_dir=data_dir\n",
    "    )\n",
    "\n",
    "    datapath = Path(datapath)\n",
    "    logger.info(f\"Data is downloaded to {datapath}.\")\n",
    "    return datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 12:08:33.975 | INFO     | __main__:get_eeg:8 - Data is downloaded to ../data/raw/datasets/eeg_data.\n"
     ]
    }
   ],
   "source": [
    "df = get_eeg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "\n",
    "class BaseDataset:\n",
    "    def __init__(self, datapath: Path) -> None:\n",
    "        self.path = datapath\n",
    "        self.data =  self.process_data()\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        data = arff.loadarff(self.path)\n",
    "        cur_label = int(data[0][0][14]) #index 14 = label\n",
    "        EEG_list = [] #Lege lijst waarin meerdere observaties worden opgeslagen\n",
    "        EEG_full = [] #Lege lijst waarin meerdere batches in worden samengevoegd.\n",
    "        for obs in data[0]:\n",
    "            if int(obs[14]) == cur_label:\n",
    "                EEG_dim = [] #Lege lijst waarin de EEG_dim van een bepaalde observatie in kunnen worden opgeslagen.\n",
    "                for index, i in enumerate(obs):\n",
    "                    if index != 14:\n",
    "                        EEG_dim.append(i)\n",
    "                EEG_dim = torch.Tensor(EEG_dim)\n",
    "                EEG_list.append(EEG_dim)\n",
    "            else:\n",
    "                EEG_full_label = (cur_label, torch.stack(EEG_list))\n",
    "                EEG_full.append(EEG_full_label)\n",
    "                cur_label = int(obs[14])\n",
    "                EEG_list = [] #Lege lijst waarin meerdere observaties in kunnen worden opgeslagen.\n",
    "                EEG_dim = [] #Lege lijst waarin de EEG_dim van een bepaalde observatie in kunnen worden opgeslagen.\n",
    "                for index, i in enumerate(obs):\n",
    "                    if index != 14:\n",
    "                        EEG_dim.append(i)\n",
    "                EEG_dim = torch.Tensor(EEG_dim)\n",
    "                EEG_list.append(EEG_dim)\n",
    "        EEG_full_label = (cur_label, torch.stack(EEG_list))\n",
    "        EEG_full.append(EEG_full_label)\n",
    "        return EEG_full\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "   \n",
    "    def __getitem__(self, idx: int) -> Tuple:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-10 12:23:50.063 | INFO     | __main__:get_eeg:8 - Data is downloaded to ../data/raw/datasets/eeg_data.\n"
     ]
    }
   ],
   "source": [
    "dataloader = BaseDataset(datapath=get_eeg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " index_list = np.random.permutation(len(dataloader))\n",
    " index = 0\n",
    "x, y = dataloader[int(index_list[index])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "         4393.8501],\n",
       "        [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "         4384.1001],\n",
       "        [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "         4389.2300],\n",
       "        ...,\n",
       "        [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "         4571.7900],\n",
       "        [4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "         4558.4600],\n",
       "        [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "         4549.2300]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDatastreamer:\n",
    "    \"\"\"This datastreamer wil never stop\n",
    "    The dataset should have a:\n",
    "        __len__ method\n",
    "        __getitem__ method\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: BaseDataset,\n",
    "        batchsize: int,\n",
    "        preprocessor: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.data =  self.window()\n",
    "        self.batchsize = batchsize\n",
    "        self.preprocessor = preprocessor\n",
    "        self.size = len(self.dataset)\n",
    "        self.reset_index()\n",
    "        \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(len(self.data) / self.batchsize)\n",
    "    \n",
    "    def window(self) -> None:\n",
    "        data = self.dataset\n",
    "        list2 = []\n",
    "        for i in range(24):\n",
    "            n_window = len(data[i][1]) - 5 + 1\n",
    "            time = torch.arange(0, 5).reshape(1, -1)\n",
    "            window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "            idx = time + window\n",
    "            test = data[i][1][idx]\n",
    "            test2 = (data[i][0], test)\n",
    "            list2.append(test2)\n",
    "        return list2\n",
    "        \n",
    "\n",
    "    def reset_index(self) -> None:\n",
    "        self.index_list = np.random.permutation(self.size)\n",
    "        self.index = 0\n",
    "\n",
    "    def batchloop(self) -> Sequence[Tuple]:\n",
    "        batch = []\n",
    "        for _ in range(self.batchsize):\n",
    "            x, y = self.data[int(self.index_list[self.index])]\n",
    "            batch.append((x, y))\n",
    "            self.index += 1\n",
    "        return batch\n",
    "\n",
    "    def stream(self) -> Iterator:\n",
    "        while True:\n",
    "            if self.index > (self.size - self.batchsize):\n",
    "                self.reset_index()\n",
    "            batch = self.batchloop()\n",
    "            if self.preprocessor is not None:\n",
    "                X, Y = self.preprocessor(batch)  # noqa N806\n",
    "            else:\n",
    "                X, Y = zip(*batch)  # noqa N806\n",
    "            yield X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataIterator:\n",
    "    \"\"\"This iterator will consume all data and stop automatically.\n",
    "    The dataset should have a:\n",
    "        __len__ method\n",
    "        __getitem__ method\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: BaseDataset, batchsize: int) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.data = self.window()\n",
    "        self.batchsize = batchsize\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(len(self.data) / self.batchsize)\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator:\n",
    "        self.index = 0\n",
    "        self.index_list = torch.randperm(len(self.data))\n",
    "        return self\n",
    "    \n",
    "    def window(self) -> None:\n",
    "        data = self.dataset\n",
    "        list2 = []\n",
    "        for i in range(24):\n",
    "            n_window = len(data[i][1]) - 5 + 1\n",
    "            time = torch.arange(0, 5).reshape(1, -1)\n",
    "            window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "            idx = time + window\n",
    "            test = data[i][1][idx]\n",
    "            test2 = (data[i][0], test)\n",
    "            list2.append(test2)\n",
    "        return list2\n",
    "\n",
    "    def batchloop(self) -> Tuple[List, List]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        for _ in range(self.batchsize):\n",
    "            x, y = self.data[int(self.index_list[self.index])]\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "            self.index += 1\n",
    "        return X, Y\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.data) - self.batchsize):\n",
    "            X, Y = self.batchloop()  # noqa N806\n",
    "            return torch.tensor(X), torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = BaseDataIterator(dataloader,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([184, 5, 14])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = test[0]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddedDatagenerator(BaseDataIterator):\n",
    "    \"\"\"Iterator with additional padding of X\n",
    "\n",
    "    Args:\n",
    "        BaseDataIterator (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data: BaseDataset, batchsize: int) -> None:\n",
    "        super().__init__(data, batchsize)\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.data) - self.batchsize):\n",
    "            X, Y = self.batchloop()  # noqa N806\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0)  # noqa N806\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = PaddedDatagenerator(test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([180, 5, 5, 14])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = test2[0]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(x: Tensor, n_time: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Generates and index that can be used to window a timeseries.\n",
    "    E.g. the single series [0, 1, 2, 3, 4, 5] can be windowed into 4 timeseries with\n",
    "    length 3 like this:\n",
    "\n",
    "    [0, 1, 2]\n",
    "    [1, 2, 3]\n",
    "    [2, 3, 4]\n",
    "    [3, 4, 5]\n",
    "\n",
    "    We now can feed 4 different timeseries into the model, instead of 1, all\n",
    "    with the same length.\n",
    "    \"\"\"\n",
    "    n_window = len(x) - n_time + 1\n",
    "    time = torch.arange(0, n_time).reshape(1, -1)\n",
    "    window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "    idx = time + window\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "         4393.8501],\n",
       "        [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "         4384.1001],\n",
       "        [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "         4389.2300],\n",
       "        ...,\n",
       "        [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "         4571.7900],\n",
       "        [4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "         4558.4600],\n",
       "        [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "         4549.2300]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataloader)):\n",
    "    test_list =[]\n",
    "    n_window = len(dataloader[i][1]) - 5 + 1\n",
    "    time = torch.arange(0, 5).reshape(1, -1)\n",
    "    window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "    idx = time + window\n",
    "    test = dataloader[i][1][idx]\n",
    "    #test_list.append(test)\n",
    "    #test_full = (dataloader[i][0], torch.stack(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def window2(dataloader) -> None:\n",
    "        for i in range(len(data)):\n",
    "            x, y = data[int(index_list[index])]\n",
    "            test_list =[]\n",
    "            n_window = len(y[i]) - 5 + 1\n",
    "            time = torch.arange(0, 5).reshape(1, -1)\n",
    "            window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "            idx = time + window\n",
    "            test = y[i][idx]\n",
    "            test_list.append(test)\n",
    "            test_full = (x, torch.stack(test_list))\n",
    "        return test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def window(dataloader) -> None:\n",
    "        data = dataloader\n",
    "        for i in range(0, len(data len(data)):\n",
    "            test_list =[]\n",
    "            n_window = len(data[i][1]) - 5 + 1\n",
    "            time = torch.arange(0, 5).reshape(1, -1)\n",
    "            window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "            idx = time + window\n",
    "            test = data[i][1][idx]\n",
    "            test_list.append(test)\n",
    "            test_full = (data[i][0], torch.stack(test_list))\n",
    "        return test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind(dataloader):\n",
    "    data = dataloader\n",
    "    test_list =[]\n",
    "    for i in range(len(data),len(data[i][1])):    \n",
    "        n_window = len(data[i][1]) - 5 + 1\n",
    "        time = torch.arange(0, 5).reshape(1, -1)\n",
    "        window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "        idx = time + window\n",
    "        test.append(i\n",
    "        test = data[i][1][idx]\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([184, 5, 14])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1732/4207954328.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test = torch.tensor(test)\n"
     ]
    }
   ],
   "source": [
    "list2 = []\n",
    "for i in range(24):\n",
    "    n_window = len(dataloader[i][1]) - 5 + 1\n",
    "    time = torch.arange(0, 5).reshape(1, -1)\n",
    "    window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "    idx = time + window\n",
    "    test = dataloader[i][1][idx]\n",
    "    test2 = (dataloader[i][0], test)\n",
    "    list2.append(test2)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/les5/notebooks/eeg_2.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/les5/notebooks/eeg_2.ipynb#ch0000017vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mlen\u001b[39m(a)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/les5/notebooks/eeg_2.ipynb#ch0000017vscode-remote?line=1'>2</a>\u001b[0m a\u001b[39m.\u001b[39;49mshape()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "len(a)\n",
    "a.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_window = len(dataloader[0][1]) - 5 + 1\n",
    "time = torch.arange(0, 5).reshape(1, -1)\n",
    "window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "idx = time + window\n",
    "test = dataloader[0][1][idx]\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = BaseDatastreamer(dataloader,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BaseDatastreamer at 0x7f388b714910>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseDatastreamer' object has no attribute '__next__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/les5/notebooks/eeg_2.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/les5/notebooks/eeg_2.ipynb#ch0000022vscode-remote?line=0'>1</a>\u001b[0m test_1\u001b[39m.\u001b[39;49m\u001b[39m__next__\u001b[39;49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseDatastreamer' object has no attribute '__next__'"
     ]
    }
   ],
   "source": [
    "test_1.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(x: Tensor, n_time: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Generates and index that can be used to window a timeseries.\n",
    "    E.g. the single series [0, 1, 2, 3, 4, 5] can be windowed into 4 timeseries with\n",
    "    length 3 like this:\n",
    "\n",
    "    [0, 1, 2]\n",
    "    [1, 2, 3]\n",
    "    [2, 3, 4]\n",
    "    [3, 4, 5]\n",
    "\n",
    "    We now can feed 4 different timeseries into the model, instead of 1, all\n",
    "    with the same length.\n",
    "    \"\"\"\n",
    "    n_window = len(x) - n_time + 1\n",
    "    time = torch.arange(0, n_time).reshape(1, -1)\n",
    "    window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "    idx = time + window\n",
    "    return idx"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf41673808a97226fd1716a8b076843c01d654ce418b73454e0f22407fa0bee6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deep-learning-0fXQ8KaZ-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
