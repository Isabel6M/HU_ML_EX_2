{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excercise 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 16:45:17.147380: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-13 16:45:17.147422: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from typing import Callable, Dict, Iterator, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "sys.path.insert(0, \"..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haal de data op vanuit de functie in de gestructeerde folder indeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import make_dataset\n",
    "from src.data import data_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-13 16:45:20.501 | INFO     | src.data.make_dataset:get_eeg:27 - Data is downloaded to ../data/raw/datasets/eeg_data.\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset.get_eeg()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Na een verkenning van de data, komt naar voren dat de dataset uit 14 dimensies bestaat. De data wordt eerst ingeladen in chunks wanneer het label gelijk is. Hierbij wordt dus de data aan elkaar geclusterd. Dit wordt gedaan door middel van de class BaseDataset waarbij ik een functie ingebouwd heb waarbij de data wordt aangepast (process_data). Hierbij kijk ik eerst naar het huidige label (cur_label = index 14) en maak ik 2 lege lijsten aan. 1 lijst waar meerdere observaties (EEG_list) aan elkaar worden opgeslagen en 1 lijst waar alle chunks worden samengevoegd (chunks). Waarbij ik gebruik maak van een forloop en kijk telkens of het label gelijk is aan het huidige label en hierna plak ik alle observaties behalve index 14( label). Deze voeg ik toe aan de lege lijst (EEG_dim) en uiteindelijk aan de lijst buiten de forloop (EEG_list). Dit doe ik ook als het label niet gelijk is aan huidig label. Uiteindelijk voeg ik de lijsten weer bij elkaar in de list chunks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data_tools.BaseDataset(datapath=dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbij komen 24 chunks naar voren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.__len__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eerst is dus een label zichtbaar (bij item 0 > label 0) en de tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([[4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "          4393.8501],\n",
       "         [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "          4384.1001],\n",
       "         [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "          4389.2300],\n",
       "         ...,\n",
       "         [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "          4571.7900],\n",
       "         [4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "          4558.4600],\n",
       "         [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "          4549.2300]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, torch.Size([188, 14]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dataloader[0]\n",
    "x, y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbij zie je dus dat de eerste chunk uit een sequence lengte van 188 bij 14 dimensies bestaat met label 0. De tweede observatie een sequence lengte van 683 bij 14 dimensies heeft met label 1. We kunnen hierbij door middel van de window functie, telkens over elke observatie windowen en op die manier gelijke lengtes krijgen. Wel komen hier dan meerdere windows van elke observatie naar voren. De window functie heb ik aab de BaseDataIterator toegevoegd (class BaseDataIterator_wind). Hierbij heb ik als basis de window functie uit les 3 gebruikt en maak ik weer een lege lijst aan. Hierna maak ik  gebruik van een forloop waarbij ik door de 24 chunks van de dataset ga (len(self.dataset)). Ik kijk per chunk hoelang de sequence lengte is en wordt er gekeken hoevaak de window erdoor heen kan. Ik start met een window_size van 5.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_data = data_tools.BaseDataIterator_wind(dataloader, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_data.__len__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In onderstaande uitdraai zie je het eerste item in combinatie met een window van 5, waarbij het tweede gedeelte dus ook met de tweede waarde begint (4324). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([[[4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "           4393.8501],\n",
       "          [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "           4384.1001],\n",
       "          [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "           4389.2300],\n",
       "          ...,\n",
       "          [4315.8999, 4003.5901, 4257.4399,  ..., 4270.2598, 4621.5400,\n",
       "           4378.9702],\n",
       "          [4314.3599, 4005.6399, 4259.4902,  ..., 4272.3101, 4624.6201,\n",
       "           4381.5400],\n",
       "          [4324.6201, 4012.8201, 4263.0801,  ..., 4274.3599, 4632.3101,\n",
       "           4400.5098]],\n",
       " \n",
       "         [[4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "           4384.1001],\n",
       "          [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "           4389.2300],\n",
       "          [4328.7202, 4011.7900, 4296.4102,  ..., 4287.6899, 4632.3101,\n",
       "           4396.4102],\n",
       "          ...,\n",
       "          [4314.3599, 4005.6399, 4259.4902,  ..., 4272.3101, 4624.6201,\n",
       "           4381.5400],\n",
       "          [4324.6201, 4012.8201, 4263.0801,  ..., 4274.3599, 4632.3101,\n",
       "           4400.5098],\n",
       "          [4331.2798, 4024.1001, 4266.1499,  ..., 4274.3599, 4638.9702,\n",
       "           4401.5400]],\n",
       " \n",
       "         [[4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "           4389.2300],\n",
       "          [4328.7202, 4011.7900, 4296.4102,  ..., 4287.6899, 4632.3101,\n",
       "           4396.4102],\n",
       "          [4326.1499, 4011.7900, 4292.3101,  ..., 4288.2100, 4632.8198,\n",
       "           4398.4600],\n",
       "          ...,\n",
       "          [4324.6201, 4012.8201, 4263.0801,  ..., 4274.3599, 4632.3101,\n",
       "           4400.5098],\n",
       "          [4331.2798, 4024.1001, 4266.1499,  ..., 4274.3599, 4638.9702,\n",
       "           4401.5400],\n",
       "          [4326.6699, 4020.0000, 4264.1001,  ..., 4271.2798, 4634.3599,\n",
       "           4385.1299]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[4484.6201, 4155.8999, 4298.4600,  ..., 4335.3799, 4700.5098,\n",
       "           4505.1299],\n",
       "          [4483.5898, 4150.7700, 4294.3599,  ..., 4335.8999, 4714.8701,\n",
       "           4514.3599],\n",
       "          [4487.6899, 4153.3301, 4298.9702,  ..., 4337.9502, 4728.2100,\n",
       "           4521.5400],\n",
       "          ...,\n",
       "          [4454.8701, 4039.4900, 4281.0298,  ..., 4345.6401, 4796.9199,\n",
       "           4551.7900],\n",
       "          [4465.1299, 4041.5400, 4298.4600,  ..., 4358.4600, 4814.3599,\n",
       "           4566.1499],\n",
       "          [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "           4571.7900]],\n",
       " \n",
       "         [[4483.5898, 4150.7700, 4294.3599,  ..., 4335.8999, 4714.8701,\n",
       "           4514.3599],\n",
       "          [4487.6899, 4153.3301, 4298.9702,  ..., 4337.9502, 4728.2100,\n",
       "           4521.5400],\n",
       "          [4490.7700, 4153.8501, 4309.7402,  ..., 4340.0000, 4729.2300,\n",
       "           4518.9702],\n",
       "          ...,\n",
       "          [4465.1299, 4041.5400, 4298.4600,  ..., 4358.4600, 4814.3599,\n",
       "           4566.1499],\n",
       "          [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "           4571.7900],\n",
       "          [4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "           4558.4600]],\n",
       " \n",
       "         [[4487.6899, 4153.3301, 4298.9702,  ..., 4337.9502, 4728.2100,\n",
       "           4521.5400],\n",
       "          [4490.7700, 4153.8501, 4309.7402,  ..., 4340.0000, 4729.2300,\n",
       "           4518.9702],\n",
       "          [4481.5400, 4140.5098, 4309.7402,  ..., 4341.5400, 4731.2798,\n",
       "           4520.5098],\n",
       "          ...,\n",
       "          [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "           4571.7900],\n",
       "          [4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "           4558.4600],\n",
       "          [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "           4549.2300]]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_data.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([167, 22, 14])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = window_data[0]\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbij is 184 de maximale hoeveelheid slices we vanuit de array [0][1] kunnen halen met een window van 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Kijken naar de eerste observatie. Een window van 5 is klein, stel ik ga groter windowen dan kan het zijn dat sommige observaties te kort zijn. De maximale window is 22. Een window van 200 geeft bijvoorbeeld problemen. Om deze reden wordt padding toegevoegd waardoor je weet dat de observatie nooit te kort kan zijn. Deze heb ik in een aparte class (BaseDataIterator_pad) geschreven waarbij ik de functie padding gebruik. Hierbij maak ik weer een lege lijst aan waar ik met een forloop door de chunks (24) heen ga. Hierbij kijk ik telkens hoelang de sequence lengte is en bereken ik het verschil met de window size. Stel dit verschil is niet 0 dan wordt het verschil door middel van de F.pad functie toegevoegd. Als deze gelijk is aan 0 wordt er geen extra padding toegepast. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_padding = data_tools.BaseDataIterator_pad(dataloader, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_padding.__len__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([[4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "          4393.8501],\n",
       "         [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "          4384.1001],\n",
       "         [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "          4389.2300],\n",
       "         ...,\n",
       "         [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "             0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "             0.0000],\n",
       "         [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "             0.0000]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_padding.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 14])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data_padding[0]\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbij zie je dus bij de eerste observatie dat de sequence lengte is uitgebreid met 12 (naar 200). De sequence lengte was eerst 188. Hierbij moet wel rekening gehouden dat bijvoorbeeld bij de observatie met een sequence lengte van 23 er heel veel padding is. De BaseDataIterator class kun je combineren met de class van de windowing door de data_padding in te voegen in de BaseDataIterator_wind (bv. data_test = data_tools.BaseDataIterator_wind(data_padding,200)). Echter heb ik de windowing en padding gecombineerd in één functie (padding_windowing) in de class BaseDataIterator_pad_wind. In de basis zijn de voorgaande functies van windowing en padding gelijk gebleven. Hierbij zie je nu ook dat de window_size groot kan zijn (bijvoorbeeld 200). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ex2 = data_tools.BaseDataIterator_pad_wind(dataloader, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([[[4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "           4393.8501],\n",
       "          [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "           4384.1001],\n",
       "          [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "           4389.2300],\n",
       "          ...,\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000],\n",
       "          [   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "              0.0000]]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ex2.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, torch.Size([1, 200, 14]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data_ex2[0]\n",
    "x, y.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deep-learning-E14Cnx23-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16b8f312320cd240106b9ea4d318428341e8727b3c7d5fc1f73cfe4a3d9868ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
